{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9462fbd",
   "metadata": {},
   "source": [
    "### Predictive Insights from Portuguese Bank Marketing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5dd85d",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed08af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d562d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_bank = pd.read_csv('data_bank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8d769fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
      "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'poutcome', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_bank.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68d8ba21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age           int64\n",
      "job          object\n",
      "marital      object\n",
      "education    object\n",
      "default      object\n",
      "balance       int64\n",
      "housing      object\n",
      "loan         object\n",
      "contact      object\n",
      "day           int64\n",
      "month        object\n",
      "duration      int64\n",
      "campaign      int64\n",
      "pdays         int64\n",
      "previous      int64\n",
      "poutcome     object\n",
      "target        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data_bank.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c310c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  target     45211 non-null  int64 \n",
      "dtypes: int64(8), object(9)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data_bank.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ccd2e7",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "Feature selection - using feature importance to choose sets top 5/10/20 and the one with \"all features\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "517814ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Features: ['balance', 'age', 'day', 'campaign', 'pdays']\n",
      "Top 10 Features: ['balance', 'age', 'day', 'campaign', 'pdays', 'poutcome_success', 'previous', 'education_secondary', 'education_tertiary', 'month_apr']\n",
      "Top 20 Features: ['balance', 'age', 'day', 'campaign', 'pdays', 'poutcome_success', 'previous', 'education_secondary', 'education_tertiary', 'month_apr', 'job_technician', 'job_management', 'poutcome_failure', 'month_mar', 'housing_no', 'marital_married', 'job_admin.', 'poutcome_other', 'month_jun', 'month_oct']\n",
      "Top 49 Features: ['balance', 'age', 'day', 'campaign', 'pdays', 'poutcome_success', 'previous', 'education_secondary', 'education_tertiary', 'month_apr', 'job_technician', 'job_management', 'poutcome_failure', 'month_mar', 'housing_no', 'marital_married', 'job_admin.', 'poutcome_other', 'month_jun', 'month_oct', 'job_blue-collar', 'housing_yes', 'marital_single', 'month_aug', 'contact_cellular', 'month_may', 'month_jul', 'education_primary', 'month_feb', 'job_services', 'marital_divorced', 'month_sep', 'month_nov', 'loan_no', 'contact_other', 'loan_yes', 'education_other', 'job_retired', 'job_self-employed', 'job_unemployed', 'month_jan', 'job_student', 'job_entrepreneur', 'contact_telephone', 'month_dec', 'job_housemaid', 'default_yes', 'default_no', 'job_other']\n",
      "+-----------------+---------------+-------------+-------------+-------------+-------+\n",
      "|                 | Feature Set   | Feature 1   | Feature 2   | Feature 3   | ...   |\n",
      "+=================+===============+=============+=============+=============+=======+\n",
      "| Top 5 Features  | balance       | age         | day         | campaign    | pdays |\n",
      "+-----------------+---------------+-------------+-------------+-------------+-------+\n",
      "| Top 10 Features | balance       | age         | day         | campaign    | pdays |\n",
      "+-----------------+---------------+-------------+-------------+-------------+-------+\n",
      "| Top 20 Features | balance       | age         | day         | campaign    | pdays |\n",
      "+-----------------+---------------+-------------+-------------+-------------+-------+\n",
      "| Top 49 Features | balance       | age         | day         | campaign    | pdays |\n",
      "+-----------------+---------------+-------------+-------------+-------------+-------+\n"
     ]
    }
   ],
   "source": [
    "#### Data Preparation:\n",
    "\n",
    "# Separate the features and target variable; drop 'duration' variable since it is available after the call \n",
    "X = data_bank.drop(['target','duration'], axis=1)\n",
    "y = data_bank['target']\n",
    "\n",
    "# Convert categorical variables to numerical using one-hot encoding\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "\n",
    "#### Random Forest Classifier:\n",
    "\n",
    "# Create the Random Forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#### Model Training:\n",
    "\n",
    "# Fit the classifier to the data\n",
    "rf.fit(X_encoded, y)\n",
    "\n",
    "\n",
    "#### Feature Importance:\n",
    "# Get feature importances and save it as one-dimensional array (pd.Series(values, index))\n",
    "feature_importances = pd.Series(rf.feature_importances_, index=X_encoded.columns)\n",
    "\n",
    "\n",
    "#### Feature Ranking:\n",
    "# Rank the features in descending order\n",
    "feature_ranking = feature_importances.sort_values(ascending=False)\n",
    "\n",
    "# Define the number of top features to select\n",
    "top_features = [5, 10, 20, len(X_encoded.columns)]\n",
    "\n",
    "\n",
    "\n",
    "#### Selecting Top Features:\n",
    "# Select the top features for each set\n",
    "feature_sets = {}\n",
    "for num_features in top_features:\n",
    "    selected_features = feature_ranking[:num_features].index.tolist()\n",
    "    feature_sets[f'Top {num_features} Features'] = selected_features\n",
    "  \n",
    "\n",
    " # Print the selected feature sets\n",
    "for feature_set, features in feature_sets.items():\n",
    "    print(f\"{feature_set}: {features}\")\n",
    "    \n",
    "   \n",
    " # Create a list of lists to store the feature importance table data\n",
    "table_data = []\n",
    "for feature_set, features in feature_sets.items():\n",
    "    table_data.append([feature_set] + features)\n",
    "\n",
    "# Print the table output\n",
    "headers = ['Feature Set', 'Feature 1', 'Feature 2', 'Feature 3', '...']\n",
    "print(tabulate(table_data, headers=headers, tablefmt='grid'))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b6d0a6",
   "metadata": {},
   "source": [
    "## Evaluating Feature Importance with Random Forest and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8b755ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Set: Top 5 Features\n",
      "+---------------------+------------------+---------------+-----------------+\n",
      "| Model               |   Mean Precision |   Mean Recall |   Mean F1 Score |\n",
      "+=====================+==================+===============+=================+\n",
      "| Random Forest       |         0.11047  |    0.16938    |      0.101975   |\n",
      "+---------------------+------------------+---------------+-----------------+\n",
      "| Logistic Regression |         0.157143 |    0.00151229 |      0.00299348 |\n",
      "+---------------------+------------------+---------------+-----------------+\n",
      "\n",
      "Feature Set: Top 10 Features\n",
      "+---------------------+------------------+---------------+-----------------+\n",
      "| Model               |   Mean Precision |   Mean Recall |   Mean F1 Score |\n",
      "+=====================+==================+===============+=================+\n",
      "| Random Forest       |         0.109575 |      0.187905 |       0.0987039 |\n",
      "+---------------------+------------------+---------------+-----------------+\n",
      "| Logistic Regression |         0.504107 |      0.162386 |       0.173225  |\n",
      "+---------------------+------------------+---------------+-----------------+\n",
      "\n",
      "Feature Set: Top 20 Features\n",
      "+---------------------+------------------+---------------+-----------------+\n",
      "| Model               |   Mean Precision |   Mean Recall |   Mean F1 Score |\n",
      "+=====================+==================+===============+=================+\n",
      "| Random Forest       |        0.0773378 |      0.193955 |       0.0914993 |\n",
      "+---------------------+------------------+---------------+-----------------+\n",
      "| Logistic Regression |        0.328367  |      0.162195 |       0.144556  |\n",
      "+---------------------+------------------+---------------+-----------------+\n",
      "\n",
      "Feature Set: Top 49 Features\n",
      "+---------------------+------------------+---------------+-----------------+\n",
      "| Model               |   Mean Precision |   Mean Recall |   Mean F1 Score |\n",
      "+=====================+==================+===============+=================+\n",
      "| Random Forest       |        0.0280537 |      0.200192 |       0.0491013 |\n",
      "+---------------------+------------------+---------------+-----------------+\n",
      "| Logistic Regression |        0.104889  |      0.215691 |       0.0701219 |\n",
      "+---------------------+------------------+---------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Create a list of models to evaluate\n",
    "models = [\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=1000, random_state=42))\n",
    "]\n",
    "\n",
    "# Define the number of top features to select\n",
    "top_features = [5, 10, 20, len(X_encoded.columns)]\n",
    "\n",
    "# Create a StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Select the top features for each set and evaluate models\n",
    "results = {}\n",
    "\n",
    "# Fit the Random Forest model to calculate feature importance\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_encoded, y)\n",
    "feature_importances = rf_model.feature_importances_\n",
    "feature_importances_df = pd.DataFrame({'Feature': X_encoded.columns, 'Importance': feature_importances})\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "for num_features in top_features:\n",
    "    selected_features = feature_importances_df['Feature'][:num_features].tolist()\n",
    "    feature_set_name = f'Top {num_features} Features'\n",
    "\n",
    "    # Scale the selected features\n",
    "    X_selected = X_encoded[selected_features]\n",
    "    X_selected_scaled = scaler.fit_transform(X_selected)\n",
    "\n",
    "    model_results = []\n",
    "\n",
    "    for model_name, model in models:\n",
    "        scores_precision = cross_val_score(model, X_selected_scaled, y, cv=5, scoring='precision')\n",
    "        scores_recall = cross_val_score(model, X_selected_scaled, y, cv=5, scoring='recall')\n",
    "        scores_f1 = cross_val_score(model, X_selected_scaled, y, cv=5, scoring='f1')\n",
    "\n",
    "        model_results.append((model_name, scores_precision.mean(), scores_recall.mean(), scores_f1.mean()))\n",
    "\n",
    "    results[feature_set_name] = model_results\n",
    "\n",
    "# Print the results\n",
    "for feature_set_name, model_results in results.items():\n",
    "    print(f\"Feature Set: {feature_set_name}\")\n",
    "    headers = ['Model', 'Mean Precision', 'Mean Recall', 'Mean F1 Score']\n",
    "    print(tabulate(model_results, headers=headers, tablefmt='grid'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "294c74d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Specify the file path and name for the CSV file\n",
    "csv_file = 'model_results.csv'\n",
    "\n",
    "# Write the model results to the CSV file\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Feature Set', 'Model', 'Mean Precision', 'Mean Recall', 'Mean F1 Score'])\n",
    "    for feature_set_name, model_results in results.items():\n",
    "        for model_result in model_results:\n",
    "            writer.writerow([feature_set_name] + list(model_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f613f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
